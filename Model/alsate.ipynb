{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-26T13:06:07.654131Z",
     "iopub.status.busy": "2024-11-26T13:06:07.653319Z",
     "iopub.status.idle": "2024-11-26T13:07:11.014292Z",
     "shell.execute_reply": "2024-11-26T13:07:11.013198Z",
     "shell.execute_reply.started": "2024-11-26T13:06:07.654093Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -U bitsandbytes\n",
    "%pip install transformers==4.44.2\n",
    "%pip install -U accelerate\n",
    "%pip install -U peft\n",
    "%pip install -U trl\n",
    "%pip install -U wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T13:07:11.016688Z",
     "iopub.status.busy": "2024-11-26T13:07:11.016379Z",
     "iopub.status.idle": "2024-11-26T13:07:11.334813Z",
     "shell.execute_reply": "2024-11-26T13:07:11.333973Z",
     "shell.execute_reply.started": "2024-11-26T13:07:11.016660Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "hf_token = user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\n",
    "login(token = hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T13:07:11.336607Z",
     "iopub.status.busy": "2024-11-26T13:07:11.335999Z",
     "iopub.status.idle": "2024-11-26T13:07:11.341698Z",
     "shell.execute_reply": "2024-11-26T13:07:11.340858Z",
     "shell.execute_reply.started": "2024-11-26T13:07:11.336568Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model,\n",
    ")\n",
    "import os, torch, wandb\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer, setup_chat_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T13:07:11.343715Z",
     "iopub.status.busy": "2024-11-26T13:07:11.343420Z",
     "iopub.status.idle": "2024-11-26T13:07:12.522163Z",
     "shell.execute_reply": "2024-11-26T13:07:12.521575Z",
     "shell.execute_reply.started": "2024-11-26T13:07:11.343684Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241126_130711-w7rii5yb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vvce/ALSATE/runs/w7rii5yb' target=\"_blank\">ALSATE-v3</a></strong> to <a href='https://wandb.ai/vvce/ALSATE' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vvce/ALSATE' target=\"_blank\">https://wandb.ai/vvce/ALSATE</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vvce/ALSATE/runs/w7rii5yb' target=\"_blank\">https://wandb.ai/vvce/ALSATE/runs/w7rii5yb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wb_token = user_secrets.get_secret(\"wandb\")\n",
    "\n",
    "wandb.login(key=wb_token)\n",
    "run = wandb.init(\n",
    "    project='ALSATE', \n",
    "    job_type=\"training\", \n",
    "    anonymous=\"allow\",\n",
    "    name=\"ALSATE-v3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T13:07:12.523944Z",
     "iopub.status.busy": "2024-11-26T13:07:12.523325Z",
     "iopub.status.idle": "2024-11-26T13:07:12.528442Z",
     "shell.execute_reply": "2024-11-26T13:07:12.527563Z",
     "shell.execute_reply.started": "2024-11-26T13:07:12.523903Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_model = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "new_model = \"llama-3.2-3b-sys-log-analysis-alsate-v1\"\n",
    "dataset_name = \"k-arthik-r/sys-logs-L0-to-L4-12.6k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T13:07:12.530520Z",
     "iopub.status.busy": "2024-11-26T13:07:12.529693Z",
     "iopub.status.idle": "2024-11-26T13:07:12.540594Z",
     "shell.execute_reply": "2024-11-26T13:07:12.539873Z",
     "shell.execute_reply.started": "2024-11-26T13:07:12.530475Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if torch.cuda.get_device_capability()[0] >= 8:\n",
    "    !pip install -qqq flash-attn\n",
    "    torch_dtype = torch.bfloat16\n",
    "    attn_implementation = \"flash_attention_2\"\n",
    "else:\n",
    "    torch_dtype = torch.float16\n",
    "    attn_implementation = \"eager\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T13:07:12.541784Z",
     "iopub.status.busy": "2024-11-26T13:07:12.541505Z",
     "iopub.status.idle": "2024-11-26T13:07:37.626469Z",
     "shell.execute_reply": "2024-11-26T13:07:37.625545Z",
     "shell.execute_reply.started": "2024-11-26T13:07:12.541736Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe986c1691a4866ad342570c58a95cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=attn_implementation\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T13:07:37.628076Z",
     "iopub.status.busy": "2024-11-26T13:07:37.627737Z",
     "iopub.status.idle": "2024-11-26T13:07:38.683215Z",
     "shell.execute_reply": "2024-11-26T13:07:38.682311Z",
     "shell.execute_reply.started": "2024-11-26T13:07:37.628040Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(dataset_name, split=\"train\")\n",
    "dataset = dataset.shuffle(seed=65)\n",
    "\n",
    "instruction = \"\"\"\n",
    "Your name is \"ALSATE\",you are an advanced syslog parsing and analysis tool. Your task is to analyze provided system logs, identify potential causes of their generation, and detect any security threats or anomalies. If threats are found, suggest precise remediation steps. Respond only when the input is a valid system log; otherwise, reply with: 'Input does not appear to be a valid system log. Unable to assist.'\n",
    "\"\"\"\n",
    "\n",
    "def format_chat_template(row):\n",
    "    row_json = [\n",
    "        {\"role\": \"system\", \"content\": instruction},\n",
    "        {\"role\": \"user\", \"content\": row[\"Logs\"]},\n",
    "        {\"role\": \"assistant\", \"content\": row[\"Cause and Remediation\"]}\n",
    "    ]\n",
    "    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n",
    "    return row\n",
    "\n",
    "dataset = dataset.map(format_chat_template, num_proc=4)\n",
    "split_dataset = dataset.train_test_split(test_size=0.2, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T13:07:38.684785Z",
     "iopub.status.busy": "2024-11-26T13:07:38.684427Z",
     "iopub.status.idle": "2024-11-26T13:07:38.782449Z",
     "shell.execute_reply": "2024-11-26T13:07:38.781680Z",
     "shell.execute_reply.started": "2024-11-26T13:07:38.684746Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Nov 2024\\n\\nYour name is \"ALSATE\",you are an advanced syslog parsing and analysis tool. Your task is to analyze provided system logs, identify potential causes of their generation, and detect any security threats or anomalies. If threats are found, suggest precise remediation steps. Respond only when the input is a valid system log; otherwise, reply with: \\'Input does not appear to be a valid system log. Unable to assist.\\'<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nNov 24 00:49:54: Critical system failure: Network driver unable to initialize, system cannot access the network.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nCause - The network driver failed to load, preventing system connectivity.\\nRemediation - 1. Reinstall or update the network driver. 2. Check and replace hardware like the network adapter if necessary. 3. Verify network configurations for errors.<|eot_id|>'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'][1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T13:07:38.786356Z",
     "iopub.status.busy": "2024-11-26T13:07:38.786068Z",
     "iopub.status.idle": "2024-11-26T13:07:38.793749Z",
     "shell.execute_reply": "2024-11-26T13:07:38.792932Z",
     "shell.execute_reply.started": "2024-11-26T13:07:38.786313Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import bitsandbytes as bnb\n",
    "\n",
    "def find_all_linear_names(model):\n",
    "    cls = bnb.nn.Linear4bit\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    if 'lm_head' in lora_module_names:\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)\n",
    "\n",
    "modules = find_all_linear_names(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T13:07:38.795121Z",
     "iopub.status.busy": "2024-11-26T13:07:38.794799Z",
     "iopub.status.idle": "2024-11-26T13:07:45.887342Z",
     "shell.execute_reply": "2024-11-26T13:07:45.886563Z",
     "shell.execute_reply.started": "2024-11-26T13:07:38.795085Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer.chat_template = None\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=modules\n",
    ")\n",
    "model, tokenizer = setup_chat_format(model, tokenizer)\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T13:07:45.888822Z",
     "iopub.status.busy": "2024-11-26T13:07:45.888498Z",
     "iopub.status.idle": "2024-11-26T13:07:45.923327Z",
     "shell.execute_reply": "2024-11-26T13:07:45.922659Z",
     "shell.execute_reply.started": "2024-11-26T13:07:45.888793Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    output_dir=new_model,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    num_train_epochs=2,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=0.05,\n",
    "    save_steps=0.05,\n",
    "    save_total_limit=3,\n",
    "    logging_steps=1,\n",
    "    warmup_steps=1000,\n",
    "    logging_strategy=\"steps\",\n",
    "    learning_rate=2e-4,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    group_by_length=True,\n",
    "    max_grad_norm=0.8,\n",
    "    weight_decay = 0.1,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"wandb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T13:07:45.924757Z",
     "iopub.status.busy": "2024-11-26T13:07:45.924357Z",
     "iopub.status.idle": "2024-11-26T13:07:47.654425Z",
     "shell.execute_reply": "2024-11-26T13:07:47.653787Z",
     "shell.execute_reply.started": "2024-11-26T13:07:45.924729Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '0.13.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30e07e8e582485a818062b16bd6b852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2536 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=split_dataset[\"train\"],\n",
    "    eval_dataset=split_dataset[\"test\"],\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length= 512,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing= False,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T13:07:47.655596Z",
     "iopub.status.busy": "2024-11-26T13:07:47.655339Z",
     "iopub.status.idle": "2024-11-26T17:43:49.477626Z",
     "shell.execute_reply": "2024-11-26T17:43:49.476829Z",
     "shell.execute_reply.started": "2024-11-26T13:07:47.655570Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10142' max='10142' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10142/10142 4:35:58, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>508</td>\n",
       "      <td>0.668800</td>\n",
       "      <td>0.599993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1016</td>\n",
       "      <td>0.429800</td>\n",
       "      <td>0.548614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1524</td>\n",
       "      <td>0.568900</td>\n",
       "      <td>0.502780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2032</td>\n",
       "      <td>0.509700</td>\n",
       "      <td>0.476040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2540</td>\n",
       "      <td>0.430300</td>\n",
       "      <td>0.464909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3048</td>\n",
       "      <td>0.330900</td>\n",
       "      <td>0.445699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3556</td>\n",
       "      <td>0.506600</td>\n",
       "      <td>0.438191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4064</td>\n",
       "      <td>0.178200</td>\n",
       "      <td>0.426397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4572</td>\n",
       "      <td>0.411600</td>\n",
       "      <td>0.413832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5080</td>\n",
       "      <td>0.349400</td>\n",
       "      <td>0.406196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5588</td>\n",
       "      <td>0.294900</td>\n",
       "      <td>0.404868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6096</td>\n",
       "      <td>0.243100</td>\n",
       "      <td>0.398372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6604</td>\n",
       "      <td>0.277800</td>\n",
       "      <td>0.394177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7112</td>\n",
       "      <td>0.319000</td>\n",
       "      <td>0.387161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7620</td>\n",
       "      <td>0.307000</td>\n",
       "      <td>0.379753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8128</td>\n",
       "      <td>0.246700</td>\n",
       "      <td>0.375614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8636</td>\n",
       "      <td>0.296300</td>\n",
       "      <td>0.369958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9144</td>\n",
       "      <td>0.216300</td>\n",
       "      <td>0.365900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9652</td>\n",
       "      <td>0.191700</td>\n",
       "      <td>0.363560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10142, training_loss=0.42139538980872054, metrics={'train_runtime': 16559.7318, 'train_samples_per_second': 1.225, 'train_steps_per_second': 0.612, 'total_flos': 6.687393512157389e+16, 'train_loss': 0.42139538980872054, 'epoch': 1.999802819678596})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T17:43:49.479482Z",
     "iopub.status.busy": "2024-11-26T17:43:49.478932Z",
     "iopub.status.idle": "2024-11-26T17:43:50.873441Z",
     "shell.execute_reply": "2024-11-26T17:43:50.872507Z",
     "shell.execute_reply.started": "2024-11-26T17:43:49.479441Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▆▅▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▃▄▄▃▃▃▃▇▅▂▂▂▃▁▃█▂▂▆</td></tr><tr><td>eval/samples_per_second</td><td>▆▅▆▆▆▇▆▂▄▇▇▇▆█▇▁▇▇▄</td></tr><tr><td>eval/steps_per_second</td><td>▆▅▆▆▆▇▆▂▄▇▇▇▆█▇▁▇▇▄</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▆▆▇▇▇▇▇█████</td></tr><tr><td>train/grad_norm</td><td>█▅▆▆▂▃▃▃▅▅▃▂▂▃▂▂▅▂▁▁▂▃▂▃▃▂▃▁▅▂▄▄▃▃▃▂▃▂▅▂</td></tr><tr><td>train/learning_rate</td><td>▃▃▃▄▄█████▇▇▇▆▆▆▆▆▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>▆▇▄▆▆▆▅▆▄▄▃▄▄█▄▄▅▃▃▁▅▅▅▃▄▃▄▃▄▃▄▂▆▃▂▁▁▃▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.36356</td></tr><tr><td>eval/runtime</td><td>428.6051</td></tr><tr><td>eval/samples_per_second</td><td>5.917</td></tr><tr><td>eval/steps_per_second</td><td>5.917</td></tr><tr><td>total_flos</td><td>6.687393512157389e+16</td></tr><tr><td>train/epoch</td><td>1.9998</td></tr><tr><td>train/global_step</td><td>10142</td></tr><tr><td>train/grad_norm</td><td>0.55762</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>0.21</td></tr><tr><td>train_loss</td><td>0.4214</td></tr><tr><td>train_runtime</td><td>16559.7318</td></tr><tr><td>train_samples_per_second</td><td>1.225</td></tr><tr><td>train_steps_per_second</td><td>0.612</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ALSATE-v3</strong> at: <a href='https://wandb.ai/vvce/ALSATE/runs/w7rii5yb' target=\"_blank\">https://wandb.ai/vvce/ALSATE/runs/w7rii5yb</a><br/> View project at: <a href='https://wandb.ai/vvce/ALSATE' target=\"_blank\">https://wandb.ai/vvce/ALSATE</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241126_130711-w7rii5yb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T17:43:50.874942Z",
     "iopub.status.busy": "2024-11-26T17:43:50.874611Z",
     "iopub.status.idle": "2024-11-26T17:44:10.322373Z",
     "shell.execute_reply": "2024-11-26T17:44:10.321471Z",
     "shell.execute_reply.started": "2024-11-26T17:43:50.874904Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cause - The boot loader failed to initialize, causing a system crash.\n",
      "Remediation - Reinstall or repair the bootloader. Verify the integrity of the bootloader configuration and files.\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": instruction},\n",
    "    {\"role\": \"user\", \"content\": \"Nov 27 20:47:32 ubuntu kernel: Kernel panic: Failed to initialize boot loader, system crash imminent.\"}]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=150, num_return_sequences=1)\n",
    "\n",
    "text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(text.split(\"assistant\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T17:44:10.323972Z",
     "iopub.status.busy": "2024-11-26T17:44:10.323601Z",
     "iopub.status.idle": "2024-11-26T17:45:05.147272Z",
     "shell.execute_reply": "2024-11-26T17:45:05.146464Z",
     "shell.execute_reply.started": "2024-11-26T17:44:10.323940Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919d1fb126a547a99a21de3ab48a56ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/1.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/k-arthik-r/llama-3.2-3b-sys-log-analysis-alsate-v1/commit/a6a2feb1422aea50fe48ed77d184a3ed162f4c63', commit_message='Upload model', commit_description='', oid='a6a2feb1422aea50fe48ed77d184a3ed162f4c63', pr_url=None, repo_url=RepoUrl('https://huggingface.co/k-arthik-r/llama-3.2-3b-sys-log-analysis-alsate-v1', endpoint='https://huggingface.co', repo_type='model', repo_id='k-arthik-r/llama-3.2-3b-sys-log-analysis-alsate-v1'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.save_pretrained(new_model)\n",
    "trainer.model.push_to_hub(new_model, use_temp_dir=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
